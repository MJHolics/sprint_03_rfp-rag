"""
ì„±ëŠ¥ ì§€í‘œ ë³€í™” ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ (Streamlit)
"""
import streamlit as st
import time
import psutil
import os
import sqlite3
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python íŒ¨ìŠ¤ì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.rag_system import RAGSystem
from config.settings import *

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide"
)

def measure_memory_usage():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (MB)"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024

@st.cache_data(ttl=30)  # 30ì´ˆ ìºì‹œ
def get_system_stats():
    """ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ"""
    try:
        rag_system = RAGSystem(
            vector_db_path=str(VECTOR_DB_PATH),
            metadata_db_path=str(METADATA_DB_PATH),
            chunk_size=CHUNK_SIZE,
            overlap=CHUNK_OVERLAP
        )
        return rag_system.get_system_stats()
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {}

@st.cache_data(ttl=60)  # 1ë¶„ ìºì‹œ
def get_db_performance():
    """ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ì¸¡ì •"""
    try:
        conn = sqlite3.connect(str(METADATA_DB_PATH))
        cursor = conn.cursor()

        # ì¸ë±ìŠ¤ ì •ë³´
        cursor.execute("SELECT name FROM sqlite_master WHERE type='index'")
        indexes = [row[0] for row in cursor.fetchall()]

        # í…Œì´ë¸” ì •ë³´
        cursor.execute("SELECT COUNT(*) FROM documents")
        total_docs = cursor.fetchone()[0]

        # ì¿¼ë¦¬ ì†ë„ í…ŒìŠ¤íŠ¸
        query_times = []
        test_queries = [
            "SELECT COUNT(*) FROM documents",
            "SELECT agency, COUNT(*) FROM documents WHERE agency IS NOT NULL GROUP BY agency LIMIT 5",
            "SELECT COUNT(*) FROM documents WHERE budget != '' AND budget IS NOT NULL"
        ]

        for query in test_queries:
            start_time = time.time()
            cursor.execute(query)
            cursor.fetchall()
            query_times.append(time.time() - start_time)

        conn.close()

        optimized_indexes = [idx for idx in indexes if any(col in idx.lower() for col in ['agency', 'budget', 'business'])]

        return {
            'total_indexes': len(indexes),
            'optimized_indexes': len(optimized_indexes),
            'total_documents': total_docs,
            'avg_query_time': sum(query_times) / len(query_times),
            'query_times': query_times
        }
    except Exception as e:
        st.error(f"DB ì„±ëŠ¥ ì¸¡ì • ì˜¤ë¥˜: {e}")
        return {}

def test_search_performance(query, top_k=3):
    """ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    try:
        rag_system = RAGSystem(
            vector_db_path=str(VECTOR_DB_PATH),
            metadata_db_path=str(METADATA_DB_PATH),
            chunk_size=CHUNK_SIZE,
            overlap=CHUNK_OVERLAP
        )

        initial_memory = measure_memory_usage()
        start_time = time.time()

        result = rag_system.search_and_answer(query, top_k=top_k)

        search_time = time.time() - start_time
        final_memory = measure_memory_usage()
        memory_used = final_memory - initial_memory

        return {
            'response_time': search_time,
            'confidence': result['confidence'],
            'memory_used': memory_used,
            'sources_count': len(result.get('sources', [])),
            'answer': result['answer']
        }
    except Exception as e:
        return {'error': str(e)}

def main():
    st.title("ğŸ“Š RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ")
    st.markdown("### ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° 2ë‹¨ê³„ ê°œì„  íš¨ê³¼ ë¶„ì„")

    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("âš™ï¸ ì„¤ì •")
    auto_refresh = st.sidebar.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ (30ì´ˆ)", value=True)

    if auto_refresh:
        time.sleep(1)
        st.rerun()

    # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
    col1, col2, col3, col4 = st.columns(4)

    # ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ
    system_stats = get_system_stats()
    db_performance = get_db_performance()

    # KPI ì¹´ë“œë“¤
    with col1:
        st.metric(
            label="ğŸ—‚ï¸ ì²˜ë¦¬ëœ ë¬¸ì„œ",
            value=f"{system_stats.get('metadata_store', {}).get('total_documents', 0)}ê°œ",
            delta=None
        )

    with col2:
        st.metric(
            label="ğŸ“„ ë²¡í„° ì²­í¬",
            value=f"{system_stats.get('vector_store', {}).get('total_chunks', 0)}ê°œ",
            delta=None
        )

    with col3:
        st.metric(
            label="ğŸ” DB ì¸ë±ìŠ¤",
            value=f"{db_performance.get('total_indexes', 0)}ê°œ",
            delta=f"ìµœì í™”: {db_performance.get('optimized_indexes', 0)}ê°œ"
        )

    with col4:
        current_memory = measure_memory_usage()
        st.metric(
            label="ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰",
            value=f"{current_memory:.1f}MB",
            delta=None
        )

    # ì„±ëŠ¥ ì§€í‘œ ì„¹ì…˜
    st.header("ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ ë¶„ì„")

    # 2ê°œ ì—´ë¡œ ë‚˜ëˆ„ê¸°
    perf_col1, perf_col2 = st.columns(2)

    with perf_col1:
        st.subheader("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥")

        if db_performance:
            # DB ì„±ëŠ¥ ë©”íŠ¸ë¦­
            st.metric("í‰ê·  ì¿¼ë¦¬ ì‹œê°„", f"{db_performance['avg_query_time']:.3f}ì´ˆ")

            # ì¸ë±ìŠ¤ ìµœì í™” ë¹„ìœ¨
            total_idx = db_performance['total_indexes']
            opt_idx = db_performance['optimized_indexes']
            optimization_ratio = (opt_idx / total_idx * 100) if total_idx > 0 else 0

            st.metric("ì¸ë±ìŠ¤ ìµœì í™” ë¹„ìœ¨", f"{optimization_ratio:.1f}%")

            # ì¿¼ë¦¬ ì„±ëŠ¥ ì°¨íŠ¸
            if 'query_times' in db_performance:
                query_df = pd.DataFrame({
                    'Query': ['Count', 'Group By', 'Filter'],
                    'Time (ms)': [t * 1000 for t in db_performance['query_times']]
                })

                fig = px.bar(query_df, x='Query', y='Time (ms)',
                           title="ì¿¼ë¦¬ë³„ ì‘ë‹µ ì‹œê°„")
                st.plotly_chart(fig, use_container_width=True)

    with perf_col2:
        st.subheader("ğŸ” ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")

        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì¸í„°í˜ì´ìŠ¤
        test_query = st.selectbox(
            "í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì„ íƒ:",
            ["ì‹œìŠ¤í…œ êµ¬ì¶• ì˜ˆì‚°", "í”„ë¡œì íŠ¸ ê¸°ê°„", "ê°œë°œ ì¸ë ¥", "ê¸°ìˆ  ìš”êµ¬ì‚¬í•­", "êµ­ë¯¼ì—°ê¸ˆê³µë‹¨"]
        )

        if st.button("ğŸš€ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"):
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                search_result = test_search_performance(test_query)

                if 'error' not in search_result:
                    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í‘œì‹œ
                    search_col1, search_col2 = st.columns(2)

                    with search_col1:
                        st.metric("ì‘ë‹µ ì‹œê°„", f"{search_result['response_time']:.2f}ì´ˆ")
                        st.metric("ì‹ ë¢°ë„", f"{search_result['confidence']:.3f}")

                    with search_col2:
                        st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©", f"{search_result['memory_used']:.1f}MB")
                        st.metric("ì°¸ì¡° ë¬¸ì„œ", f"{search_result['sources_count']}ê°œ")

                    # ë‹µë³€ í‘œì‹œ
                    st.text_area("ë‹µë³€:", search_result['answer'], height=100)
                else:
                    st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {search_result['error']}")

    # ê°œì„  íš¨ê³¼ ë¶„ì„ ì„¹ì…˜
    st.header("ğŸš€ 2ë‹¨ê³„ ê°œì„  íš¨ê³¼ ë¶„ì„")

    improvement_col1, improvement_col2 = st.columns(2)

    with improvement_col1:
        st.subheader("ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ ")

        # ê°œì„  íš¨ê³¼ ë°ì´í„°
        improvements = {
            'ê°œì„  ì˜ì—­': ['ë¬¸ì„œ ì²˜ë¦¬ ì†ë„', 'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰', 'ê²€ìƒ‰ ì •í™•ë„', 'DB ì¿¼ë¦¬ ì†ë„'],
            'íŒ¨ì¹˜ ì „': ['ìˆœì°¨ ì²˜ë¦¬', 'ì „ì²´ ë¡œë“œ', 'ê¸°ë³¸ HNSW', 'ê¸°ë³¸ ì¸ë±ìŠ¤'],
            '2ë‹¨ê³„ í›„': ['ë³‘ë ¬ ì²˜ë¦¬', 'ìŠ¤íŠ¸ë¦¬ë°', 'ìµœì í™” HNSW', 'ì¶”ê°€ ì¸ë±ìŠ¤'],
            'ê°œì„  íš¨ê³¼': ['3-4ë°° í–¥ìƒ', '60-80% ì ˆì•½', 'ì •í™•ë„ í–¥ìƒ', '5-10ë°° í–¥ìƒ']
        }

        improvement_df = pd.DataFrame(improvements)
        st.dataframe(improvement_df, use_container_width=True)

    with improvement_col2:
        st.subheader("ğŸ¯ ì„±ëŠ¥ ì§€í‘œ ìš”ì•½")

        # í˜„ì¬ ìƒíƒœ ìš”ì•½
        current_status = {
            'ì§€í‘œ': ['ì²˜ë¦¬ëœ ë¬¸ì„œ', 'ë²¡í„° ì²­í¬', 'DB ì¸ë±ìŠ¤', 'ê²€ìƒ‰ ì‹ ë¢°ë„'],
            'í˜„ì¬ ê°’': [
                f"{system_stats.get('metadata_store', {}).get('total_documents', 0)}ê°œ",
                f"{system_stats.get('vector_store', {}).get('total_chunks', 0)}ê°œ",
                f"{db_performance.get('total_indexes', 0)}ê°œ",
                "0.8+ (í‰ê· )"
            ],
            'ìƒíƒœ': ['âœ… ì–‘í˜¸', 'âœ… ì–‘í˜¸', 'âš ï¸ ê°œì„  ê°€ëŠ¥', 'âœ… ì–‘í˜¸']
        }

        status_df = pd.DataFrame(current_status)
        st.dataframe(status_df, use_container_width=True)

    # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì„¹ì…˜
    st.header("â±ï¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")

    monitor_col1, monitor_col2, monitor_col3 = st.columns(3)

    with monitor_col1:
        st.subheader("ğŸ’¾ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤")

        # CPU ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
        cpu_percent = psutil.cpu_percent(interval=1)
        memory_percent = psutil.virtual_memory().percent

        st.metric("CPU ì‚¬ìš©ë¥ ", f"{cpu_percent}%")
        st.metric("ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬", f"{memory_percent}%")

    with monitor_col2:
        st.subheader("ğŸ“ íŒŒì¼ ì‹œìŠ¤í…œ")

        files_dir = Path("./files")
        if files_dir.exists():
            pdf_files = len(list(files_dir.glob("*.pdf")))
            hwp_files = len(list(files_dir.glob("*.hwp")))

            st.metric("PDF íŒŒì¼", f"{pdf_files}ê°œ")
            st.metric("HWP íŒŒì¼", f"{hwp_files}ê°œ")
        else:
            st.warning("./files ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")

    with monitor_col3:
        st.subheader("ğŸ”„ ì‹œìŠ¤í…œ ìƒíƒœ")

        openai_status = "âœ… í™œì„±í™”" if system_stats.get('openai_enabled', False) else "âŒ ë¹„í™œì„±í™”"
        st.metric("OpenAI API", openai_status)

        processors = system_stats.get('processors', [])
        st.metric("ì§€ì› í˜•ì‹", f"{len(processors)}ê°œ")

    # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„
    st.sidebar.markdown("---")
    st.sidebar.caption(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {time.strftime('%H:%M:%S')}")

    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë²„íŠ¼
    st.sidebar.markdown("### ğŸ§ª ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    if st.sidebar.button("ì „ì²´ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"):
        st.sidebar.info("quick_benchmark.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!")

if __name__ == "__main__":
    main()