"""
HWP ë¬¸ì„œ ì²˜ë¦¬ê¸°
pyhwpxë¥¼ ì‚¬ìš©í•œ ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ì‹ êµ¬í˜„
"""
import os
import tempfile
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Union

from .base import DocumentProcessor, DocumentChunk, TableImageChunk

class HWPProcessor(DocumentProcessor):
    """HWP ë¬¸ì„œ ì²˜ë¦¬ê¸° (pyhwpx ì‚¬ìš©)"""
    
    # í‘œ ë¶„í•  ìƒìˆ˜
    CROP_HEIGHT_PX = 1000   # í‘œ ë¶„í•  ë†’ì´ ê¸°ì¤€ (í”½ì…€)
    OVERLAP_HEIGHT = 100  # ë¶„í•  ì‹œ ê²¹ì¹¨ ë†’ì´ (í”½ì…€)

    def __init__(self, chunk_size: int = 1000, overlap: int = 200, 
                 extract_table_images: bool = False, xhtml_dir: Optional[str] = None):
        super().__init__(chunk_size, overlap)
        self.supported_extensions = ['.hwp']
        self.extract_table_images = extract_table_images
        self.xhtml_dir = xhtml_dir
        
        # í‘œ ì´ë¯¸ì§€ ì¶”ì¶œì´ í™œì„±í™”ëœ ê²½ìš° í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
        if self.extract_table_images:
            self._import_table_processing_libraries()

    def _import_table_processing_libraries(self):
        """í‘œ ì²˜ë¦¬ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ë™ì ìœ¼ë¡œ ì„í¬íŠ¸"""
        try:
            global BeautifulSoup, webdriver, ChromeDriverManager, By, WebDriverWait, expected_conditions
            global Image, Service
            
            from bs4 import BeautifulSoup
            from selenium import webdriver
            from selenium.webdriver.chrome.service import Service
            from webdriver_manager.chrome import ChromeDriverManager
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions
            from PIL import Image
            
            print("í‘œ ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")
        except ImportError as e:
            print(f"í‘œ ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("pip install selenium webdriver-manager beautifulsoup4 pillow openai ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
            self.extract_table_images = False

    def extract_content(self, file_path: str) -> Dict[str, Any]:
        """HWP íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ë° í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        print(f"HWP íŒŒì¼ ì²˜ë¦¬ ì‹œë„: {Path(file_path).name}")

        # 1. ê¸°ì¡´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text_content = self._extract_hwp_text(file_path)

        # 2. í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ (ì˜µì…˜)
        table_images = []
        if self.extract_table_images and self.xhtml_dir:
            try:
                xhtml_path = self._find_corresponding_xhtml(file_path)
                if xhtml_path:
                    # í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ
                    table_images = self._extract_table_images_from_xhtml(xhtml_path, text_content)
                    print(f"í‘œ ì´ë¯¸ì§€ {len(table_images)}ê°œ ì¶”ì¶œ ì™„ë£Œ (ëŒ€í™”í˜• GPT ë¶„ì„ í¬í•¨)")
                else:
                    print(f"ëŒ€ì‘í•˜ëŠ” XHTML íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            except Exception as e:
                print(f"í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = self._create_base_metadata(file_path)
        metadata.update({
            "source_type": "hwp",
            "extraction_method": "hybrid_with_tables" if table_images else "text_only",
            "table_count": len(table_images)
        })

        return {
            "text": text_content,
            "table_images": table_images,
            "metadata": metadata
        }

    def _extract_hwp_text(self, file_path: str) -> str:
        """HWP íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ - ê¸°ì¡´ ë¡œì§"""
        # 1. olefile ë°©ë²• ì‹œë„
        text_content = self._extract_with_olefile(file_path)

        # 2. ì‹¤íŒ¨ ì‹œ ë°”ì´ë„ˆë¦¬ íŒ¨í„´ ë°©ë²• ì‹œë„
        if not text_content or len(text_content.strip()) < 10:
            text_content = self._extract_with_binary_pattern(file_path)

        # 3. ì—¬ì „íˆ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€
        if not text_content or len(text_content.strip()) < 10:
            text_content = f"HWP íŒŒì¼ '{Path(file_path).name}'ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì•”í˜¸í™”ë˜ì–´ ìˆê±°ë‚˜ ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

        return text_content

    def _extract_with_olefile(self, file_path: str) -> str:
        """olefileì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            import olefile

            if not olefile.isOleFile(file_path):
                return ""

            ole = olefile.OleFileIO(file_path)

            # PrvText ìŠ¤íŠ¸ë¦¼ ì°¾ê¸°
            for stream_path in ole.listdir():
                if isinstance(stream_path, list) and 'PrvText' in str(stream_path):
                    try:
                        # ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ ë°ì´í„° ì½ê¸°
                        with ole.openfilepath(stream_path) as f:
                            raw_data = f.read()

                        # UTF-16LEë¡œ ë””ì½”ë”© ì‹œë„ (HWPì˜ ì¼ë°˜ì ì¸ ì¸ì½”ë”©)
                        if len(raw_data) > 2:
                            try:
                                text = raw_data.decode('utf-16le')
                                cleaned = self._clean_hwp_text(text)
                                if len(cleaned.strip()) > 10:
                                    ole.close()
                                    return cleaned
                            except:
                                pass

                    except Exception:
                        continue

            ole.close()
            return ""

        except Exception:
            return ""

    def _extract_with_binary_pattern(self, file_path: str) -> str:
        """ë°”ì´ë„ˆë¦¬ íŒ¨í„´ì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            with open(file_path, 'rb') as f:
                data = f.read()

            # í•œê¸€ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ UTF-16 íŒ¨í„´ ì°¾ê¸°
            text_parts = []

            # UTF-16LE íŒ¨í„´ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¡°ê° ì°¾ê¸°
            i = 0
            while i < len(data) - 1:
                if data[i] != 0:  # ì²« ë²ˆì§¸ ë°”ì´íŠ¸ê°€ 0ì´ ì•„ë‹ˆê³ 
                    if i + 1 < len(data) and data[i + 1] == 0:  # ë‘ ë²ˆì§¸ ë°”ì´íŠ¸ê°€ 0ì´ë©´
                        # ì—°ì†ëœ UTF-16LE ë¬¸ìì—´ ì°¾ê¸°
                        start = i
                        while i < len(data) - 1:
                            if data[i] != 0 and data[i + 1] == 0:
                                i += 2
                            else:
                                break

                        if i - start > 20:  # ì¶©ë¶„íˆ ê¸´ í…ìŠ¤íŠ¸ ì¡°ê°
                            try:
                                text_chunk = data[start:i].decode('utf-16le')
                                # í•œê¸€ì´ë‚˜ ì˜ë¬¸ì´ í¬í•¨ëœ ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                                if any(ord(c) >= 0xAC00 and ord(c) <= 0xD7A3 for c in text_chunk) or \
                                   any(c.isalpha() for c in text_chunk):
                                    text_parts.append(text_chunk)
                            except:
                                pass
                i += 1

            if text_parts:
                combined_text = ' '.join(text_parts)
                return self._clean_hwp_text(combined_text)

            return ""

        except Exception:
            return ""

    def chunk_content(self, content: Dict[str, Any]) -> List[Union[DocumentChunk, TableImageChunk]]:
        """HWP ë‚´ìš©ì„ í…ìŠ¤íŠ¸ ì²­í¬ì™€ í‘œ ì´ë¯¸ì§€ ì²­í¬ë¡œ ë¶„í• """
        text = content["text"]
        table_images = content.get("table_images", [])
        metadata = content["metadata"]

        # 1. í…ìŠ¤íŠ¸ ì²­í‚¹
        text_chunks = self._smart_chunk_text(text, metadata)

        # HWP íŠ¹í™” ë©”íƒ€ë°ì´í„° ì¶”ê°€
        for chunk in text_chunks:
            chunk.metadata.update({
                "source_type": "hwp",
                "chunk_type": "text",
                "extraction_method": metadata.get("extraction_method", "text_only")
            })

        # 2. í‘œ ì´ë¯¸ì§€ ì²­í‚¹ (ì˜µì…˜)
        table_chunks = []
        if table_images:
            table_chunks = self._create_table_image_chunks(table_images, metadata)

        # 3. ì²­í¬ ê²°í•© (í…ìŠ¤íŠ¸ ì²­í¬ + í‘œ ì´ë¯¸ì§€ ì²­í¬)
        all_chunks = text_chunks + table_chunks

        # ì²­í¬ ì¸ë±ìŠ¤ ì¬ì •ë ¬
        for i, chunk in enumerate(all_chunks):
            chunk.chunk_index = i

        print(f"ì´ ì²­í¬ ìƒì„±: {len(text_chunks)}ê°œ í…ìŠ¤íŠ¸ + {len(table_chunks)}ê°œ í‘œ ì´ë¯¸ì§€")
        return all_chunks

    def _clean_hwp_text(self, raw_text: str) -> str:
        """HWPì—ì„œ ì¶”ì¶œëœ ì›ì‹œ í…ìŠ¤íŠ¸ ì •ë¦¬"""
        import re

        if not raw_text:
            return ""

        # ë„ ë¬¸ì ì œê±°
        text = raw_text.replace('\x00', '')

        # ì œì–´ ë¬¸ì ì œê±° (ë‹¨, ê°œí–‰ê³¼ íƒ­ì€ ìœ ì§€)
        text = re.sub(r'[\x01-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)

        # ì—°ì†ëœ ê³µë°± ì •ë¦¬
        text = re.sub(r' +', ' ', text)

        # ì—°ì†ëœ ê°œí–‰ ì •ë¦¬ (ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ)
        text = re.sub(r'\n{3,}', '\n\n', text)

        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()

        return text

    def _extract_hwp_metadata_patterns(self, text: str) -> Dict[str, Any]:
        """HWP ë¬¸ì„œì—ì„œ íŠ¹í™” ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        import re

        extracted = {}

        # HWP ë¬¸ì„œ íŠ¹ìœ ì˜ íŒ¨í„´ë“¤
        patterns = {
            'hwp_version': r'HWP\s*(\d+\.\d+)',
            'creation_date': r'ì‘ì„±ì¼\s*[:\s]*(\d{4}[.-]\d{1,2}[.-]\d{1,2})',
            'department': r'ë¶€ì„œ\s*[:\s]*([^\n]+)',
            'document_number': r'ë¬¸ì„œë²ˆí˜¸\s*[:\s]*([^\n]+)'
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                extracted[key] = match.group(1).strip()

        return extracted

    def _find_corresponding_xhtml(self, hwp_path: str) -> Optional[str]:
        """HWP íŒŒì¼ì— ëŒ€ì‘í•˜ëŠ” XHTML íŒŒì¼ ì°¾ê¸°"""
        hwp_filename = Path(hwp_path).stem  # í™•ì¥ì ì œê±°
        xhtml_dir = Path(self.xhtml_dir)
        
        # .xhtml íŒŒì¼ ë¨¼ì € ì‹œë„
        xhtml_path = xhtml_dir / f"{hwp_filename}.xhtml"
        if xhtml_path.exists():
            return str(xhtml_path)
        
        return None

    def _extract_table_images_from_xhtml(self, xhtml_path: str, document_text: str = "") -> List[Dict]:
        """XHTMLì—ì„œ í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ (ë¬¸ì„œ ì „ì²´ ë§¥ë½ ê¸°ë°˜)"""
        if not self.extract_table_images:
            return []
        
        try:
            with open(xhtml_path, 'r', encoding='utf-8') as f:
                soup = BeautifulSoup(f.read(), 'html.parser')
        except Exception as e:
            print(f"XHTML íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            return []
        
        tables = soup.find_all('table')
        if not tables:
            print("XHTMLì—ì„œ í‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        print(f"XHTMLì—ì„œ {len(tables)}ê°œ í‘œ ë°œê²¬")
        table_data_list = []
        
        for i, table in enumerate(tables):
            try:
                # 1. í‘œ ì•ë’¤ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
                preceding_text, following_text = self._extract_table_context(soup, table)
                
                # 2. Standalone HTML ìƒì„±
                standalone_html = self._create_standalone_table_html(table, i)
                
                # 3. í‘œ ë†’ì´ ì²´í¬ í›„ ë¶„í• /ë‹¨ì¼ ì²˜ë¦¬ ê²°ì •
                image_parts = self._split_table_by_pixels(standalone_html)
                
                # ë¶„í•  ì—¬ë¶€ í™•ì¸
                is_split = len(image_parts) > 1
                
                # í•˜ë‚˜ì˜ í‘œ â†’ í•˜ë‚˜ì˜ table_dataë¡œ ì²˜ë¦¬ (GPT ì„¤ëª…ì€ ë‚˜ì¤‘ì— ì¼ê´„ ìƒì„±)
                table_data_list.append({
                    'image_data': image_parts[0],  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ (í˜¸í™˜ì„±)
                    'image_parts': image_parts,    # ëª¨ë“  ë¶„í• ëœ ì´ë¯¸ì§€ë“¤
                    'gpt_description': "",         # ë‚˜ì¤‘ì— ëŒ€í™”í˜• ë°©ì‹ìœ¼ë¡œ ìƒì„±
                    'table_html': str(table),
                    'table_index': i,
                    'preceding_context': preceding_text,
                    'following_context': following_text,
                    # ë¶„í•  ê´€ë ¨ ì •ë³´
                    'is_split_table': is_split,
                    'total_parts': len(image_parts),
                    'overlap_height': self.OVERLAP_HEIGHT if is_split else 0
                })
                
                print(f"í‘œ {i+1}/{len(tables)} ì²˜ë¦¬ ì™„ë£Œ")
                
            except Exception as e:
                print(f"í‘œ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        # ëª¨ë“  í‘œ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ í›„ ëŒ€í™”í˜• GPT ë¶„ì„ ìˆ˜í–‰
        if table_data_list and document_text:
            print(f"ğŸ“Š {len(table_data_list)}ê°œ í‘œì— ëŒ€í•œ ëŒ€í™”í˜• GPT ë¶„ì„ ì‹œì‘...")
            try:
                descriptions = self._generate_all_table_descriptions_conversation_style(
                    document_text, table_data_list
                )
                
                # ìƒì„±ëœ ì„¤ëª…ì„ ê° í‘œì— í• ë‹¹
                for i, description in enumerate(descriptions):
                    if i < len(table_data_list):
                        table_data_list[i]['gpt_description'] = description
                        
                print(f"âœ… ëŒ€í™”í˜• GPT ë¶„ì„ ì™„ë£Œ!")
                
            except Exception as e:
                print(f"âŒ ëŒ€í™”í˜• GPT ë¶„ì„ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¤ëª…ìœ¼ë¡œ í´ë°±
                for i, table_data in enumerate(table_data_list):
                    if not table_data.get('gpt_description'):
                        table_data['gpt_description'] = f"í‘œ {i+1}: ë¶„ì„ ì‹¤íŒ¨"
        
        return table_data_list

    def _extract_table_context(self, soup, table_element):
        """í‘œ ì•ë’¤ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        preceding_text = ""
        following_text = ""
        
        try:
            # í‘œ ì• í…ìŠ¤íŠ¸ ì¶”ì¶œ
            current = table_element
            while current and len(preceding_text) < 500:
                prev_sibling = current.previous_sibling
                if prev_sibling:
                    if hasattr(prev_sibling, 'get_text'):
                        text = prev_sibling.get_text().strip()
                        if text:
                            preceding_text = text + " " + preceding_text
                    current = prev_sibling
                else:
                    current = current.parent
                    if current == soup:  # ë£¨íŠ¸ì— ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨
                        break
            
            # í‘œ ë’¤ í…ìŠ¤íŠ¸ ì¶”ì¶œ  
            current = table_element
            while current and len(following_text) < 500:
                next_sibling = current.next_sibling
                if next_sibling:
                    if hasattr(next_sibling, 'get_text'):
                        text = next_sibling.get_text().strip()
                        if text:
                            following_text = following_text + " " + text
                    current = next_sibling
                else:
                    current = current.parent
                    if current == soup:  # ë£¨íŠ¸ì— ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨
                        break
        except Exception as e:
            print(f"ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return preceding_text.strip(), following_text.strip()

    def _create_standalone_table_html(self, table_soup, table_index: int) -> str:
        """ê¹”ë”í•œ í‘œ ì „ìš© HTML ìƒì„±"""
        html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <style>
                body {{ 
                    font-family: 'Malgun Gothic', 'Microsoft YaHei', Arial, sans-serif; 
                    margin: 10px; 
                    background-color: white;
                    font-size: 16px; /* ê¸€ì í¬ê¸° ì¦ê°€ */
                    line-height: 1.4; /* ì¤„ ê°„ê²© ì¶”ê°€ */
                }}
                table {{ 
                    border-collapse: collapse; 
                    width: auto;   
                    margin: 0 auto;
                }}
                th, td {{ 
                    border: 1px solid #333; 
                    padding: 6px 10px;   /* íŒ¨ë”© ì¦ê°€ */
                    text-align: left;
                    vertical-align: middle;
                    word-wrap: break-word;
                    font-size: 15px; /* ì…€ ë‚´ ê¸€ì í¬ê¸° ëª…ì‹œì  ì„¤ì • */
                    line-height: 1.3;
                }}
                th {{ 
                    background-color: #f5f5f5; 
                    font-weight: bold; 
                }}
                tr:nth-child(even) {{
                    background-color: #fafafa;
                }}
                /* ì…€ ë‚´ë¶€ p íƒœê·¸ ì—¬ë°± ì œê±° */
                td p, th p {{
                    margin: 0;
                }}
            </style>
        </head>
        <body>
            {table_html}
        </body>
        </html>
        """
        return html_template.format(table_html=str(table_soup))

    def _split_table_by_pixels(self, html_content: str) -> List[bytes]:
        """í‘œë¥¼ í”½ì…€ ë‹¨ìœ„ë¡œ ì„¸ë¡œ ë¶„í• í•˜ì—¬ ì—¬ëŸ¬ ì´ë¯¸ì§€ë¡œ ìƒì„±"""
        try:
            import tempfile
            import os
            import io
            from PIL import Image

            # Chrome ì˜µì…˜ (ê¸°ì¡´ê³¼ ë™ì¼)
            options = webdriver.ChromeOptions()
            options.add_argument("--headless")
            options.add_argument("--no-sandbox")
            options.add_argument("--disable-dev-shm-usage")
            options.add_argument("--force-device-scale-factor=1.5")
            options.add_argument("--disable-web-security")

            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)

            try:
                # HTMLì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(mode="w", suffix=".html", delete=False, encoding="utf-8") as f:
                    f.write(html_content)
                    temp_html_path = f.name

                driver.get(f"file://{temp_html_path}")

                # í‘œ ìš”ì†Œ ëŒ€ê¸°
                table_element = WebDriverWait(driver, 10).until(
                    expected_conditions.presence_of_element_located((By.TAG_NAME, "table"))
                )

                # í‘œ í¬ê¸° ê³„ì‚° (ê¸°ì¡´ ë¡œì§ ë³´ì¡´)
                table_rect = table_element.rect
                table_width = int(table_rect["width"])
                table_height = int(table_rect["height"])

                # ê¸°ì¡´ ë„ˆë¹„ ì„¤ì • ë³´ì¡´
                min_width = 1000
                min_height = 700
                max_width = 2400
                
                final_width = max(min_width, min(table_width + 100, max_width))
                final_height = max(min_height, table_height + 300)
                
                driver.set_window_size(final_width, final_height)
                driver.execute_script("arguments[0].scrollIntoView();", table_element)

                # ì „ì²´ í‘œ ìŠ¤í¬ë¦°ìƒ· ë¨¼ì € ì´¬ì˜
                full_screenshot = table_element.screenshot_as_png
                full_img = Image.open(io.BytesIO(full_screenshot))

                # ê¸°ì¡´ ë„ˆë¹„ ì¡°ì • ë¡œì§ ë³´ì¡´
                if full_img.width > 1800:
                    scale = 1800 / full_img.width
                    new_size = (1800, int(full_img.height * scale))
                    full_img = full_img.resize(new_size, Image.LANCZOS)

                # ë¶„í•  ë¡œì§
                image_parts = []
                img_height = full_img.height
                
                # CROP_HEIGHT_PX ì´ˆê³¼ ì‹œì—ë§Œ ë¶„í• 
                if img_height <= self.CROP_HEIGHT_PX:
                    # ë¶„í•  ë¶ˆí•„ìš”
                    img_bytes = io.BytesIO()
                    full_img.save(img_bytes, format="PNG")
                    return [img_bytes.getvalue()]

                # ë¶„í•  ì‹¤í–‰
                current_y = 0
                part_number = 0
                
                while current_y < img_height:
                    part_number += 1
                    
                    # ë§ˆì§€ë§‰ ë¶€ë¶„ ì²˜ë¦¬
                    if current_y + self.CROP_HEIGHT_PX >= img_height:
                        # ë§ˆì§€ë§‰ ì¡°ê°ì€ ëê¹Œì§€
                        end_y = img_height
                        start_y = max(0, end_y - self.CROP_HEIGHT_PX)
                    else:
                        # ì¼ë°˜ì ì¸ ë¶„í• 
                        start_y = current_y
                        end_y = current_y + self.CROP_HEIGHT_PX
                    
                    # ì´ë¯¸ì§€ ìë¥´ê¸°
                    cropped_img = full_img.crop((0, start_y, full_img.width, end_y))
                    
                    # PNGë¡œ ë³€í™˜
                    img_bytes = io.BytesIO()
                    cropped_img.save(img_bytes, format="PNG")
                    image_parts.append(img_bytes.getvalue())
                    
                    # ë‹¤ìŒ ì‹œì‘ì  (ê²¹ì¹¨ ê³ ë ¤)
                    current_y = end_y - self.OVERLAP_HEIGHT
                    
                    # ë¬´í•œë£¨í”„ ë°©ì§€
                    if current_y >= img_height - self.OVERLAP_HEIGHT:
                        break

                return image_parts

            finally:
                driver.quit()
                try:
                    os.unlink(temp_html_path)
                except:
                    pass

        except Exception as e:
            print(f"í‘œ ë¶„í•  ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
            return [self._screenshot_table_html(html_content)]

    def _screenshot_table_html(self, html_content: str) -> bytes:
        """Seleniumìœ¼ë¡œ í‘œ HTML ì „ì²´ ìŠ¤í¬ë¦°ìƒ·"""
        try:
            import tempfile
            import os
            import io
            from PIL import Image

            # Chrome ì˜µì…˜
            options = webdriver.ChromeOptions()
            options.add_argument("--headless")
            options.add_argument("--no-sandbox")
            options.add_argument("--disable-dev-shm-usage")
            options.add_argument("--force-device-scale-factor=1.5")  # ê³ í•´ìƒë„ ë Œë”ë§
            options.add_argument("--disable-web-security")  # ë¡œì»¬ íŒŒì¼ ì ‘ê·¼ ê°œì„ 

            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)

            try:
                # HTMLì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(mode="w", suffix=".html", delete=False, encoding="utf-8") as f:
                    f.write(html_content)
                    temp_html_path = f.name

                driver.get(f"file://{temp_html_path}")

                # í‘œ ìš”ì†Œ ëŒ€ê¸°
                table_element = WebDriverWait(driver, 10).until(
                    expected_conditions.presence_of_element_located((By.TAG_NAME, "table"))
                )

                # í‘œ í¬ê¸° ê³„ì‚°
                table_rect = table_element.rect
                table_width = int(table_rect["width"])
                table_height = int(table_rect["height"])

                # ìµœì†Œ í¬ê¸° ë³´ì¥ ë° ìœˆë„ìš° í¬ê¸° ì„¤ì •
                min_width = 1000   # ìµœì†Œ ë„ˆë¹„ ë³´ì¥
                min_height = 700   # ìµœì†Œ ë†’ì´ ë³´ì¥
                max_width = 2400   # ìµœëŒ€ ë„ˆë¹„ ì¦ê°€ (1500 â†’ 2400)
                
                final_width = max(min_width, min(table_width + 100, max_width))
                final_height = max(min_height, table_height + 300)
                
                driver.set_window_size(final_width, final_height)

                # í‘œ ìŠ¤í¬ë¡¤ ë§ì¶”ê¸°
                driver.execute_script("arguments[0].scrollIntoView();", table_element)

                # í‘œ ì˜ì—­ ìŠ¤í¬ë¦°ìƒ·
                screenshot = table_element.screenshot_as_png

                # í•„ìš”ì‹œ í¬ê¸° ì¡°ì • (ê°€ë¡œí­ 1800px ë§ì¶¤ìœ¼ë¡œ ì¦ê°€)
                img = Image.open(io.BytesIO(screenshot))
                if img.width > 1800:  # 1200 â†’ 1800ìœ¼ë¡œ ì¦ê°€
                    scale = 1800 / img.width
                    new_size = (1800, int(img.height * scale))
                    img = img.resize(new_size, Image.LANCZOS)

                img_bytes = io.BytesIO()
                img.save(img_bytes, format="PNG")
                return img_bytes.getvalue()

            finally:
                driver.quit()
                try:
                    os.unlink(temp_html_path)
                except:
                    pass

        except Exception as e:
            print(f"ìŠ¤í¬ë¦°ìƒ· ìƒì„± ì‹¤íŒ¨: {e}")
            try:
                img = Image.new("RGB", (800, 400), color="white")  # ê¸°ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì¦ê°€
                img_bytes = io.BytesIO()
                img.save(img_bytes, format="PNG")
                return img_bytes.getvalue()
            except:
                return b""


    def _summarize_document_if_needed(self, document_text: str) -> str:
        """ë¬¸ì„œê°€ ë„ˆë¬´ ê¸¸ë©´ í•µì‹¬ ë‚´ìš©ë§Œ ìš”ì•½"""
        if len(document_text) > 30000:  # ì•½ 20K í† í°
            print("  ğŸ“„ ë¬¸ì„œê°€ ê¸¸ì–´ì„œ í•µì‹¬ ë‚´ìš©ë§Œ ìš”ì•½ ì¤‘...")
            lines = document_text.split('\n')
            important_lines = []
            
            for line in lines:
                line = line.strip()
                if len(line) < 10:  # ë„ˆë¬´ ì§§ì€ ë¼ì¸ ì œì™¸
                    continue
                    
                # ì œëª©ì´ë‚˜ ì¤‘ìš”í•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¼ì¸ë§Œ ì„ íƒ
                if any(keyword in line for keyword in [
                    'ì œì•ˆ', 'ëª©ì ', 'ê°œìš”', 'ìš”ì•½', 'ê²°ë¡ ', 'ì‚¬ì—…', 'í”„ë¡œì íŠ¸', 
                    'ë°°ê²½', 'í•„ìš”ì„±', 'ëª©í‘œ', 'ë²”ìœ„', 'ë‚´ìš©', 'ë°©ë²•', 'ê³„íš',
                    'ì˜ˆì‚°', 'ì¼ì •', 'íŒ€', 'ì¡°ì§', 'ê¸°ëŒ€íš¨ê³¼', 'ì„±ê³¼'
                ]):
                    important_lines.append(line)
                    
                # ìµœëŒ€ 150ì¤„ë¡œ ì œí•œ
                if len(important_lines) >= 150:
                    break
            
            summary = '\n'.join(important_lines)
            print(f"    ğŸ“„ ìš”ì•½ ì™„ë£Œ: {len(document_text):,}ì â†’ {len(summary):,}ì")
            return summary
        
        return document_text

    def _generate_all_table_descriptions_conversation_style(self, 
                                                           document_text: str, 
                                                           table_data_list: List[Dict]) -> List[str]:
        """ëŒ€í™”í˜• ë°©ì‹ìœ¼ë¡œ ëª¨ë“  í‘œ ì„¤ëª… ìƒì„±"""
        try:
            import base64
            from openai import OpenAI
            
            client = OpenAI()
            
            # 1. ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ë¬¸ì„œ ì „ì²´ ë§¥ë½ ì„¤ì •
            messages = [
                {
                    "role": "system",
                    "content": f"""ë‹¹ì‹ ì€ ì œì•ˆì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì œì•ˆì„œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

**ì œì•ˆì„œ ì „ì²´ ë‚´ìš©:**
{self._summarize_document_if_needed(document_text)}

ì´ì œ ì´ ë¬¸ì„œì˜ í‘œë“¤ì„ í•˜ë‚˜ì”© ë³´ì—¬ë“œë¦´ í…Œë‹ˆ, ê° í‘œì— ëŒ€í•´ ìƒì„¸í•œ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë¬¸ì„œ ì „ì²´ ë§¥ë½ì—ì„œ ê° í‘œì˜ ì—­í• ê³¼ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ê° í‘œë§ˆë‹¤ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
â€¢ í‘œ ì œëª©/ì£¼ì œ: 
â€¢ ë¬¸ì„œì—ì„œì˜ ì—­í• : 
â€¢ ì£¼ìš” ì»¬ëŸ¼ê³¼ ë°ì´í„°: 
â€¢ í•µì‹¬ ë‚´ìš©: 
â€¢ ê²€ìƒ‰ í‚¤ì›Œë“œ: 
â€¢ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸: """
                }
            ]
            
            descriptions = []
            
            # 2. ê° í‘œë¥¼ í•˜ë‚˜ì”© ëŒ€í™”ë¡œ ì²˜ë¦¬
            for i, table_data in enumerate(table_data_list):
                try:
                    print(f"  ğŸ“Š í‘œ {i+1}/{len(table_data_list)} GPT ë¶„ì„ ì¤‘...")
                    
                    # í˜„ì¬ í‘œì— ëŒ€í•œ ì§ˆë¬¸ ì¶”ê°€
                    user_message = {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": f"í‘œ {i+1}/{len(table_data_list)}ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."
                            }
                        ]
                    }
                    
                    # ë¶„í• ëœ í‘œì¸ ê²½ìš° ëª¨ë“  ì´ë¯¸ì§€ ì¶”ê°€, ì•„ë‹ˆë©´ ë‹¨ì¼ ì´ë¯¸ì§€
                    image_parts = table_data.get('image_parts', [])
                    for img_data in image_parts:
                        user_message["content"].append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{base64.b64encode(img_data).decode()}"
                            }
                        })
                    
                    messages.append(user_message)
                    
                    # 3. GPT ì‘ë‹µ ë°›ê¸°
                    response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=messages,
                        max_tokens=800,
                        temperature=0.3
                    )
                    
                    description = response.choices[0].message.content.strip()
                    descriptions.append(description)
                    
                    # 4. GPT ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ (ë§¥ë½ ëˆ„ì )
                    messages.append({
                        "role": "assistant", 
                        "content": description
                    })
                    
                    print(f"    âœ… í‘œ {i+1} ë¶„ì„ ì™„ë£Œ ({len(description)}ì)")
                    
                except Exception as e:
                    print(f"    âŒ í‘œ {i+1} ë¶„ì„ ì‹¤íŒ¨: {e}")
                    descriptions.append(f"í‘œ {i+1}: ë¶„ì„ ì‹¤íŒ¨ - {str(e)}")
            
            return descriptions
            
        except Exception as e:
            print(f"ëŒ€í™”í˜• GPT ë¶„ì„ ì „ì²´ ì‹¤íŒ¨: {e}")
            return [f"í‘œ {i+1}: ì „ì²´ ë¶„ì„ ì‹¤íŒ¨" for i in range(len(table_data_list))]

    def _generate_table_description_with_context(self, image_data: bytes, 
                                               preceding_text: str, 
                                               following_text: str) -> str:
        """GPT Vision APIë¡œ í‘œ ì´ë¯¸ì§€ ë¶„ì„ (ì•ë’¤ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)"""
        try:
            import base64
            from openai import OpenAI
            
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            client = OpenAI()  # API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´
            
            # ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ì •ë¦¬ (ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°)
            preceding = preceding_text[-300:] if len(preceding_text) > 300 else preceding_text
            following = following_text[:300] if len(following_text) > 300 else following_text
            
            context_prompt = f"""
ì´ í‘œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìƒì„¸í•œ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸:**
- í‘œ ì• ë‚´ìš©: "{preceding.strip()}"
- í‘œ ë’¤ ë‚´ìš©: "{following.strip()}"

**ë¶„ì„ ìš”ì²­ì‚¬í•­:**
1. í‘œì˜ ì£¼ì œì™€ ëª©ì 
2. ì£¼ìš” ì»¬ëŸ¼ê³¼ ë°ì´í„° ìœ í˜•
3. í•µì‹¬ ë‚´ìš©ê³¼ ì¤‘ìš”í•œ ìˆ˜ì¹˜
4. ì•ë’¤ í…ìŠ¤íŠ¸ì™€ì˜ ì—°ê´€ì„±
5. ì´ í‘œê°€ ë¬¸ì„œì—ì„œ ë‹´ë‹¹í•˜ëŠ” ì—­í• 

ê²€ìƒ‰ê³¼ ì´í•´ì— ë„ì›€ì´ ë˜ë„ë¡ êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
            
            # ìƒˆ ë²„ì „ API í˜¸ì¶œ ë°©ì‹
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user", 
                        "content": [
                            {
                                "type": "text",
                                "text": context_prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{base64.b64encode(image_data).decode()}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=600
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"GPT Vision API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            # Fallback: ê¸°ë³¸ ì„¤ëª… ë°˜í™˜
            return f"í‘œ ì´ë¯¸ì§€ (í¬ê¸°: {len(image_data)} bytes). " + \
                   f"ì»¨í…ìŠ¤íŠ¸: {preceding[:100]}... â†’ í‘œ â†’ {following[:100]}..."

    def _create_table_image_chunks(self, table_images: List[Dict], base_metadata: Dict) -> List[TableImageChunk]:
        """í‘œ ì´ë¯¸ì§€ë“¤ì„ TableImageChunkë¡œ ë³€í™˜"""
        chunks = []
        
        for i, table_data in enumerate(table_images):
            try:
                # TableImageChunk ìƒì„±
                chunk_metadata = {
                    **base_metadata,
                    "chunk_type": "table_image", 
                    "table_index": table_data.get("table_index", i),
                    "has_image": True,
                    "extraction_method": "gpt_vision_with_context",
                    "preceding_context": table_data.get("preceding_context", ""),
                    "following_context": table_data.get("following_context", ""),
                    # ë¶„í•  ê´€ë ¨ ë©”íƒ€ë°ì´í„°
                    "is_split_table": table_data.get("is_split_table", False),
                    "total_parts": table_data.get("total_parts", 1),
                    "overlap_height": table_data.get("overlap_height", 0)
                }
                
                chunk = TableImageChunk(
                    content=table_data.get("gpt_description", ""),
                    metadata=chunk_metadata,
                    chunk_id="",  # __post_init__ì—ì„œ ìë™ ìƒì„±
                    document_id=base_metadata.get('document_id', 'unknown'),
                    chunk_index=i,
                    
                    # í‘œ íŠ¹í™” í•„ë“œë“¤
                    table_html=table_data.get('table_html', ''),
                    image_data=table_data.get('image_data', b''),
                    gpt_description=table_data.get('gpt_description', ''),
                    
                    # ë¶„í•  ê´€ë ¨ í•„ë“œë“¤
                    image_parts=table_data.get('image_parts'),
                    is_split_table=table_data.get('is_split_table', False),
                    total_parts=table_data.get('total_parts', 1),
                    overlap_height=table_data.get('overlap_height', 0)
                )
                
                chunks.append(chunk)
                
            except Exception as e:
                print(f"í‘œ {i} ì²­í¬ ìƒì„± ì‹¤íŒ¨: {e}")
                continue
        
        return chunks